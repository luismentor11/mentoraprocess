import os
import streamlit as st
from openai import OpenAI
import tempfile
import base64

# ---------------- CONFIG ----------------
st.set_page_config(
    page_title="Mentora Roleplay Coach",
    page_icon="üé≠",
    layout="centered"
)

st.title("üé≠ Mentora Roleplay Coach ‚Äî Versi√≥n con Voz")
st.caption("Habl√° con el coach. Conversaci√≥n en tiempo real, simulaci√≥n realista.")

st.markdown("""
### Pod√©s usar:
- üé§ **Voz** (recomendado)  
- ‚å®Ô∏è **Texto tradicional**

Cuando hables, el coach entiende tu intenci√≥n y responde con voz y texto.
""")

# ---------------- API KEY ----------------
api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")

if not api_key:
    st.error("‚ö†Ô∏è Falta la API Key. Cargala en *Secrets* de Streamlit Cloud.")
    st.stop()

client = OpenAI(api_key=api_key)

# ---------------- ESTADO ----------------
if "roleplay_messages" not in st.session_state:
    st.session_state.roleplay_messages = [
        {
            "role": "system",
            "content": """
Sos Mentora Roleplay Coach. Trabaj√°s con voice + texto.
Sos directo, emp√°tico, brutal honesto, estilo argentino.

FLUJO:
1. Diagn√≥stico con preguntas cortas.
2. Resumen del escenario.
3. Simulaci√≥n realista (modo personaje).
4. Feedback cuando el usuario diga: pausa / feedback / cerrar.

Respond√© SIEMPRE en texto + un mensaje breve para TTS.
"""
        },
        {
            "role": "assistant",
            "content": "Hola, ¬øqu√© conversaci√≥n quer√©s practicar hoy?"
        }
    ]


# ---------------- FUNCIONES DE AUDIO ----------------

def play_audio_from_bytes(audio_bytes):
    """Reproduce audio en Streamlit desde bytes sin archivos externos."""
    b64 = base64.b64encode(audio_bytes).decode()
    audio_html = f"""
        <audio controls autoplay>
            <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
        </audio>
    """
    st.markdown(audio_html, unsafe_allow_html=True)


def tts(text):
    """Convierte texto en audio (voz natural OpenAI)."""
    response = client.audio.speech.create(
        model="gpt-4o-mini-tts",
        voice="alloy",
        input=text
    )
    return response.read()


def transcribe(audio_file):
    """Convierte voz a texto (Whisper)."""
    transcript = client.audio.transcriptions.create(
        model="whisper-1",
        file=audio_file
    )
    return transcript.text


# ---------------- HISTORIAL ----------------
st.subheader("üí¨ Conversaci√≥n")

for msg in st.session_state.roleplay_messages:
    if msg["role"] == "system":
        continue
    with st.chat_message("assistant" if msg["role"] == "assistant" else "user"):
        st.markdown(msg["content"])


# ---------------- INPUT DE VOZ ----------------
st.subheader("üé§ Hablar con el Coach")

audio = st.audio_input("Apret√° para grabar")

if audio is not None:
    st.write("‚è≥ Procesando audio...")
    with tempfile.NamedTemporaryFile(delete=False) as tmp:
        tmp.write(audio.read())
        audio_path = tmp.name

    # transcribir
    user_text = transcribe(audio_path)

    st.session_state.roleplay_messages.append({"role": "user", "content": user_text})
    st.chat_message("user").markdown(f"üé§ **Vos dijiste:** {user_text}")

    # responder
    with st.chat_message("assistant"):
        with st.spinner("Pensando respuesta..."):
            response = client.chat.completions.create(
                model="gpt-4.1",
                messages=st.session_state.roleplay_messages,
                temperature=0.8
            )

            ai_text = response.choices[0].message.content
            st.markdown(ai_text)

            st.session_state.roleplay_messages.append(
                {"role": "assistant", "content": ai_text}
            )

            # generar voz
            audio_bytes = tts(ai_text)
            play_audio_from_bytes(audio_bytes)


# ---------------- INPUT DE TEXTO ----------------
text_input = st.chat_input("O escrib√≠ ac√° la respuesta...")

if text_input:
    st.session_state.roleplay_messages.append({"role": "user", "content": text_input})
    st.chat_message("user").markdown(text_input)

    with st.chat_message("assistant"):
        with st.spinner("Pensando respuesta..."):
            response = client.chat.completions.create(
                model="gpt-4.1",
                messages=st.session_state.roleplay_messages,
                temperature=0.8
            )

            ai_text = response.choices[0].message.content
            st.markdown(ai_text)

            st.session_state.roleplay_messages.append(
                {"role": "assistant", "content": ai_text}
            )

            # voz
            audio_bytes = tts(ai_text)
            play_audio_from_bytes(audio_bytes)


# ---------------- SIDEBAR ----------------
st.sidebar.subheader("‚öôÔ∏è Opciones")
if st.sidebar.button("üîÑ Reiniciar conversaci√≥n"):
    st.session_state.roleplay_messages = [
        st.session_state.roleplay_messages[0],
        {"role": "assistant", "content": "Reiniciamos. ¬øQu√© conversaci√≥n quer√©s practicar ahora?"}
    ]
    st.rerun()
